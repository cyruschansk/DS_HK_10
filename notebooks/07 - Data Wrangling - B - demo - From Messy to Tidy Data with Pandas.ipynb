{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load utils/imports.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from utils.styles import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load utils/plotting.py\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import cufflinks as cf\n",
    "\n",
    "init_notebook_mode()\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01b. From Messy to Tidy Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying messy datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's considered tidy data?\n",
    "\n",
    "- Each variable forms a column\n",
    "- Each observation forms a row.\n",
    "- Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the five most common problems with messy data sets? How do we fix them?\n",
    "\n",
    "#### Our messy data identification + cleaning process:\n",
    "\n",
    "- Check if it satisfies the above criteria\n",
    "- List your observations\n",
    "- The problem\n",
    "- CLEAN it!\n",
    "- Check criteria again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    What are the most common problems with messy data? Can you name them? (hidden - enter to reveal)\n",
    "\n",
    "<!---\n",
    "- Column headers are values, not variable names.\n",
    "- Multiple variables stored in one column\n",
    "- Variables are stored in both rows and columns\n",
    "- Multiple types of observational units are stored in the same table.\n",
    "- A single observational unit is stored in multiple tables.\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 - PEW Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset explores the relationship between income and religion in the US. It comes from a report produced by the _Pew Research Center_, an American think-tank that collects data on attitudes to topics ranging from religion to the internet, and produces many reports that contain datasets in this format.\n",
    "\n",
    "The dataset has three variables, **religion**, **income**, and **frequency**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = 'pew.csv'\n",
    "download_data(fn)\n",
    "pew = pd.read_csv('data/' + fn)\n",
    "grid(pew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong with this dataset? Does it satisfy the aforementioned criteria?\n",
    "\n",
    "- Is each column a variable?\n",
    "- Is each row an observation?\n",
    "- Does each observational unit (a row) form a table?\n",
    "\n",
    "### Observation:\n",
    "- **Religion** is a variable.\n",
    "- Each category of the **income** variable is presented in six separate columns.\n",
    "- **Frequency** is considered a value here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy Data #1: Column headers are values, not variable names.\n",
    "### How to fix it: \n",
    "Reshape the table with three columns: religion, income, frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape table with three columns (religion, income, frequency)\n",
    "grid(pd.melt(pew, id_vars='religion',var_name='income',value_name='frequency'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this qualify as tidy data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This form is **tidy** because **each column represents a variable** and **each row represents an observation**, in this case a demographic unit corresponding to a combination of religion and income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 - WHO Tuberculosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tuberculosis dataset comes from the World Health Organisation, and records the counts of confirmed tuberculosis cases by country, year, and demographic group. The demographic groups are broken down by sex (m, f) and age (0-14, 15-24, 25-34, 35-44, 45-54, 55-64, unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = 'tb.csv'\n",
    "download_data(fn)\n",
    "tb = pd.read_csv('data/' + fn)\n",
    "grid(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong with this dataset? Does it satisfy the aforementioned criteria?\n",
    "\n",
    "- Is each column a variable?\n",
    "- Is each row an observation?\n",
    "- Does each observational unit (a row) form a table?\n",
    "\n",
    "### Observation:\n",
    "- There are a lot of missing values\n",
    "- The m04...fu columns represent **two** variables: sex and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy data #2 - Multiple variables stored in one column\n",
    "### How to fix it:\n",
    "- First we gather up the non-variable columns:\n",
    "- Column headers in this format are often separated by a non-alphanumeric character (e.g. ., -, \\_, :), or have a fixed width format, like in this dataset. `str.split()` makes it easy to split a compound variables into individual variables. You can either pass it a regular expression to split on (the default is to split on non-alphanumeric columns), or a vector of character positions. In this case we want to split after the first character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It has 22 columns, two which are actually labels, and 20 which contain values\n",
    "tb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  reshape table with three columns (iso2, year, m04..fu, n)\n",
    "tb = pd.melt(tb, id_vars=['iso2','year'],var_name='sex_age',value_name='frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  drop missing values, \n",
    "tb.dropna(subset=['frequency'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  split m04...fu field into two variables = sex, age\n",
    "tb[['sex','age']] = tb.sex_age.str.extract('([mf])([\\d\\w]+)',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the original duplicated column\n",
    "tb = tb[['iso2','year','sex','age','frequency']]\n",
    "grid(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this qualify as tidy data?\n",
    "Storing the values in this form resolves a problem in the original data. We want to compare rates, not counts, which means we need to know the population. In the original format, there is no easy way to add a population variable. It has to be stored in a separate table, which makes it hard to correctly match populations to counts. In tidy form, adding variables for population and rate is easy because they’re just additional columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 - Global Historical Climatology Network Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads daily weather data from the Global Historical Climatology Network for one weather station (MX17004) in \n",
    "Mexico for five months in 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = 'weather.csv'\n",
    "download_data(fn)\n",
    "weather = pd.read_csv('data/' + fn)\n",
    "grid(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong with this dataset? Does it satisfy the aforementioned criteria?\n",
    "\n",
    "- Is each column a variable?\n",
    "- Is each row an observation?\n",
    "- Does each observational unit (a row) form a table?\n",
    "\n",
    "### Observation:\n",
    "- id, year, month are variables in individual columns. That is fine.\n",
    "- But there are variables spread across columns (i.e. day) as well as variables across rows (i.e. tmax and tmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Answer (hidden)\n",
    "\n",
    "<!-- Variables are stored in both rows and columns -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy data #3 - Variables are stored in both rows and columns\n",
    "### How to fix it:\n",
    "\n",
    "- We first gather the day columns:\n",
    "- We also drop the missing values, making them implicit rather than explicit. This is ok because we know how many days are in each month and can easily reconstruct the explicit missing values. \n",
    "- This dataset is mostly tidy, but the element column is not a variable; it stores the names of variables. (Not shown in this example are the other meteorological variables prcp (precipitation) and snow (snowfall)). Fixing this requires the spread operation. This performs the inverse of gathering by spreading the element and value columns back out into the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make *day* a variable\n",
    "w = pd.melt(weather, id_vars=weather.columns[:4].tolist(),var_name='day')\n",
    "# drop the leading 'd' in the value\n",
    "w.day = w.day.str.replace('d','')\n",
    "# spread *element* and *value* columns into two variables: tmax and tmin\n",
    "labels = w.columns[:5].tolist()\n",
    "wd = w.groupby(labels).sum().unstack(level=3).swaplevel(axis=1).reset_index()\n",
    "wd.columns = wd.columns.droplevel(1)\n",
    "# drop missing values\n",
    "grid(wd.dropna().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this qualify as tidy data?\n",
    "This form is tidy: there’s one variable in each column, and each row represents one day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4  - BIllboard Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Billboard dataset shown below records the date a song first entered the billboard top 100. It has variables for artist, track, date.entered, rank and week. The rank in each week after it enters the top 100 is recorded in 75 columns, wk1 to wk75. This form of storage is not tidy, but it is useful for data entry. It reduces duplication since otherwise each song in each week would need its own row, and song metadata like title and artist would need to be repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "billboard = pd.read_csv(\"https://raw.githubusercontent.com/hadley/tidy-data/master/data/billboard.csv\")\n",
    "grid(billboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong with this dataset? Does it satisfy the aforementioned criteria?\n",
    "\n",
    "- Is each column a variable?\n",
    "- Is each row an observation?\n",
    "- Does each observational unit (a row) form a table?\n",
    "\n",
    "### Observation:\n",
    "- There is duplication of facts about the song: artist, year, and time are repeated many times. (because one artist can have many top hits)\n",
    "- This results in two types of observational units / records: One stores the song metadata (i.e. artist, year, name, time, genre). The other type is its ranking in the charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Answer (hidden)\n",
    "\n",
    "<!---\n",
    "Multiple types of observational unit in one table? \n",
    "The two types: The song and its rank in each week\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy data #4 - Multiple types of observational unit in one table\n",
    "\n",
    "Each observational unit should be stored in its own table. This is closely related to the idea of database normalisation, where each fact is expressed in only one place. It’s important because otherwise inconsistencies can arise.\n",
    "\n",
    "### How to fix it:\n",
    "\n",
    "First, tidy the data.\n",
    "\n",
    "We first need to tidy up by making **week** and **rank** variables / columns. Feel free to drop any missing values as they represent weeks that the song wasn't in the charts. Convert the week variable to an int, perhaps also figuring out the date corresponding to each week on the charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO make week and rank variables\n",
    "# TIP : Select the columns you want to melt.\n",
    "\n",
    "# TODO drop missing values\n",
    "\n",
    "# TODO calculate the date from the week variable+year\n",
    "# TIP : Are you familiar with pandas to_datetime and to_timedelta ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Answer (hidden)\n",
    "\n",
    "<!--- \n",
    "```python\n",
    "# TODO make week and rank variables\n",
    "\n",
    "# Helper function to gather the columns we want to melt\n",
    "def gather( df, key, value, cols):\n",
    "    id_vars = [ col for col in df.columns if col not in cols ]\n",
    "    id_values = cols\n",
    "    var_name = key\n",
    "    value_name = value\n",
    "    return pd.melt( df, id_vars, id_values, var_name, value_name )\n",
    "\n",
    "# Select the columns to melt - the ones containing '.week'\n",
    "cols = billboard.columns[billboard.columns.str.contains('.week')].tolist()\n",
    "# Melt the week columns\n",
    "bb = gather(billboard,'week','rank',cols)\n",
    "# Clean up Week\n",
    "bb.week = bb.week.str.extract('(\\d)').astype(int)\n",
    "\n",
    "# TODO drop missing values\n",
    "bb = bb.dropna()\n",
    "\n",
    "# TODO calculate the date from the week variable+year\n",
    "bb.date = pd.to_datetime(bb['date.entered']) + pd.to_timedelta(bb.week, unit='w')\n",
    "\n",
    "```\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need to break this dataset into two pieces: a song dataset which stores artist, song name and time, and a ranking dataset which gives the rank of the song in each week. \n",
    "\n",
    "- We first extract a song dataset:\n",
    "- Then use that to make a rank dataset by replacing repeated song facts with a pointer to song details (a unique song id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO extract song dataset with columns: artist, track, year, time. And give it a UID (song_id)\n",
    "# TIP : Use the index of grouped objects as the UID\n",
    "\n",
    "# TODO extra rank dataset with columnrs song_id date, week, rank. Set up a pointer to song details.\n",
    "# Merge datasets in a selective way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Answer (hidden)\n",
    "\n",
    "<!--- \n",
    "```python\n",
    "# TODO extract song dataset with columns: artist, track, year, time. And give it a UID (song_id)\n",
    "\n",
    "# Sort values for clarity\n",
    "bb = bb.sort_values(['artist.inverted','track','week'])\n",
    "# User index of grouped items as UID\n",
    "songs = bb.groupby(['artist.inverted','track'],as_index=False).head(1).reset_index().ix[:,:6]\n",
    "# Clean up columns\n",
    "song_cols = \"song_id year artist track time genre\".split()\n",
    "songs.columns = song_cols\n",
    "\n",
    "# TODO extra rank dataset with columnrs song_id date, week, rank. Set up a pointer to song details.\n",
    "\n",
    "# Merge song_id back in, but only keep selected columns\n",
    "rank_cols = \"song_id date week rank\".split(' ')\n",
    "rankings = bb.merge(songs)[rank_cols]\n",
    "\n",
    "# Results\n",
    "songs.head(10)\n",
    "# rankings.head(10)\n",
    "```\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What kind of data structure is this?\n",
    "\n",
    "Answer (hidden)\n",
    "<!--- relational data model --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation is useful for tidying and eliminating inconsistencies. However, there are few data analysis tools that work directly with relational data, so analysis usually also requires denormalisation or the merging the datasets back into one table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5 - Babynames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s also common to find data values about a single type of observational unit spread out over multiple tables or files. \n",
    "These tables and files are often split up by another variable, so that each represents a single year, person, or location. \n",
    "\n",
    "e.g. Take 129 yearly baby name tables provided by the US Social Security Administration and combine them into a single table/file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy data #5 - A single observational unit is stored in multiple tables.\n",
    "\n",
    "### How to fix it:\n",
    " As long as the format for individual records is consistent, this is an easy problem to fix:\n",
    "\n",
    "- Read the files into a list of tables.\n",
    "\n",
    "- For each table, add a new column that records the original file name (the file name is often the value of an important variable).\n",
    "\n",
    "- Combine all tables into a single table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\n",
    "\n",
    "http://www.prometheusresearch.com/good-data-management-practices-for-data-analysis-tidy-data-part-2/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
